## How can journalists use digital tools to better report on online mis- and disinformation?
In the week following former President Donald Trump’s suspension from major social media platforms, several national news outlets published stories reporting a 73% drop in misinformation on social media. <br/>

<img src="/images/image1.PNG" alt="alt text" width="400px" height="400px"> <br/>
The original report from research firm Zignal Labs had context for definition of “misinformation,” how that term was quantified, and the pitfalls of those measurements. 
However, what was ultimately circulated widely on social media platforms and on cable news was a watered-down headline that removed key context:<br/>
![Image](/images/image2.PNG)<br/>

<audio controls>
  <source src="images/audio1.mp3" type="audio/mpeg">
Your browser does not support the audio element.
</audio>

This soundbite, unfortunately, lacks some key context and nuance present in the article, making for a very interesting case study of misinformation reporting.
Twitter suspended over 70,000 accounts in the week after President Trump’s ban, and number of them were not “key allies” of Trump. Many were active or otherwise influential QAnon accounts or even affiliated with unrelated groups, so one can’t make a causal claim from just the Trump suspension. <br/>
Furthermore, the precise measurement of misinformation is problematic.  Though Suspending Pres. Trump’s account likely took a dent out of mis- and disinformation on Twitter, the 73% number is incredibly misleading. We still haven’t quantified yet know the impact of those suspensions, and we certainly hadn’t quantified it in any meaningful way just a week later. The only thing we know for sure is that it likely slowed a certain kind of election fraud discourse.<br/>
Using a precise percentage point for an inherently murky figure – per the Zignal Labs report, “misinformation” was measured through keyword terms – is deeply misleading. In a nutshell, a journalist shouldn’t be making claims with precise numbers when the underlying methods are so imprecise. <br/>
This represents the failure of editors and reporters to present information with a headline that reflected the nuance of the article. The misleading headline began to spread devoid of key context for interpreting the claims. The irony of spreading misleading content while reporting on misinformation doesn’t go unnoticed and may highlight an issue of journalism in the digital age. <br/>

### The Current State of Online Misinformation

Modern social media ecosystems, particularly Twitter, are full of unique pitfalls for journalists. Twitter can be an incredibly useful tool for finding sources, discovering new leads, and engaging with an audience. However, the platform is also rife with bad actors that seek to undermine journalistic integrity. Particularly thorny are “strategic information operations,” which are defined in the paper <em> Disinformation as Collaborative Work: Surfacing the Participatory Nature of Strategic Information Operations </em> as efforts by individuals and groups to manipulate and change public opinion by intentionally altering the information environment. <br/>
The primary goal of these operations is to undermine the integrity of the digital information space. These operations can be “orchestrated” by paid actors, or “organic,” arising from a series of individuals in online crowds. The paper notes a shift in recent years towards “organic” efforts. The authors also note that some operations focus on causing distraction or uncertainty in ways that “kill the possibility of debate and a reality-based politics,” rather than attempting to spread any specific message or idea. 
<br/>
As part of a case study on the disinformation campaign targeting the White Helmets amid the Syrian Civil, the paper includes a visualization that shows that particular disinformation ecosystem, which typically involved a mix of clickbait news, self-described “alternative” and “independent” media, as well as government-affiliated domains and think tanks associated with specifically pro-Russian stances. <br/>
![Image](/images/image3.PNG)
The study mentions some of the most influential accounts were Western “journalists” who grew in popularity through amplification by state-sponsored media outlets on Twitter. Work from pseudo-activists, “journalists,” media outlets, and state agencies all feed into one another, making the distinction between organic and orchestrated operations rather fuzzy. 

All these factors create a highly complicated environment for legitimate journalists, who may lack ways to quantify the credibility of individuals and groups in digital spaces. The study emphasizes that journalists are often made targets “as ‘unwitting agents’ in the spread of disinformation.” For example, anonymous sources may offer tips that align with a given journalist’s existing political beliefs. 

“Journalists and social scientists can find themselves particularly disadvantaged in these circumstances—unless there is verifiable proof of intent to deceive, these groups risk reputational, professional and legal repercussions when investigating or making claims about information operations. Meanwhile, political operatives can exploit these professionals’ cautiousness by using plausible deniability as a defense and spread misleading content without facing major threats to their own credibility.”

```markdown
“Journalists and social scientists can find themselves particularly 
disadvantaged in these circumstances — unless there is verifiable 
proof of intent to deceive, these groups risk reputational, 
professional and legal repercussions when investigating or making 
claims about information operations.Meanwhile, political operatives 
can exploit these professionals’ cautiousness by using plausible 
deniability as a defense and spread misleading content without 
facing major threats to their own credibility.”
-Disinformation as Collaborative Work: Surfacing the Participatory
Nature of Strategic Information Operations 
```

### The Mis- and Disinformation Beat

Despite the challenges of navigating digital spaces, journalists are increasingly reporting on various forms of misleading information in online ecosystems. As social media mis- and disinformation becomes grows in political relevancy, journalists must be equipped with tools to navigate and report on these worlds. 
Some internet, social media, and national security reporters have moved to cover this new "beat" full time. In doing this work, journalists aim to inform readers about what is happening online, investigate and debunk false claims, and hold social media companies accountable for the problematic information that spreads on their platforms. Compared to researchers, journalists are often exploring these issues on much shorter timelines and with fewer resources, yet they rely on some of the same kinds of data and analysis techniques. On the flip side, journalists are also facing increasing pressure to compete with citizen reporters, especially in breaking news and local event coverage.
As a result, journalists are increasingly using online spaces to search for leads, sources, statements from public officials, and information for long-term investigations. Navigating social media platforms to search for sources and investigate stories requires a new way of working that involves learning new skills and adopting new tools. 
To better support the needs of journalists, the Human-Computer Interaction research community has long been searching for ways to empower journalists with computational tools. 
In the paper <em>On the Misinformation Beat: Understanding the Work of Investigative Journalists Reporting on Problematic Information Online</em>, twelve “misinformation beat” journalists were interviewed to detail their use of digital tools.  
One of the participants of the study felt ill-equipped to report on problematic information on social platforms:

<audio controls>
  <source src="images/audio2.mp3" type="audio/mpeg">
Your browser does not support the audio element.
</audio>

(Disclaimer: this audio was a reading of the participant’s text statement found in the study)
Journalists must be constantly updating their approaches and tactics as accessibility of software and data changes, and most social media companies have little interest in supporting accessible data collection on their platforms, as another participant voiced: 

<audio controls>
  <source src="images/audio2.mp3" type="audio/mpeg">
Your browser does not support the audio element.
</audio>
(Disclaimer: this audio was a reading of the participant’s text statement found in the study)

In all twelve interviews in the study, each participant mentioned the increasing need for participants to access and analyze social data for their work. The journalists without strong data science skill sets, internal support, and effective tools for analyzing those data “felt disadvantaged in achieving their reporting goals.” 

The skills and tools necessary for this field are examined in the study <em>Examining the Digital Toolsets of Journalists Reporting on Disinformation</em>. The study identifies a few crucial uses of digital tools, which included verification of online information, tracing the spread of online content, and monitoring new and developing stories.

Each of these uses are complicated and may take a variety of forms through a variety of technologies. Information verification, for instance, can involve everything ranging from identity to the legitimacy of audiovisual content.  

The journalists interviewed in the study had access to many resources for verifying and establishing the provenance of data, but relatively fewer resources for monitoring content and drawing connections to understand information trajectories. Despite the development of journalistic digital tools, these tools are not always widely adopted by journalists due to lack of awareness, lack of access, or lack of trust in their abilities. More work needs to be done to lower the barrier of entry in this space. 


### The Rise of Data Journalism

The paper <em> Data Journalism and Misinformation </em> emphasizes that while data journalism has been envisioned to advance solid ways of knowledge in society, it is contingent on factors such as access to reliable and representative datasets and individuals with the skills to understand and analyze the data. In the study, the authors identify three key components of reliable data journalism. 
The first is access to relevant reliable datasets, though the study makes it clear that completely unbiased data does not exist and can always be interpreted in a misleading manner and even contribute to misinformation, leading to the second key component, which is the necessity of expertise. Data journalists must have the relevant expertise to process, analyze, and interpret complex data. This requires knowledge in statistics and software, as well as transparency about the process of data analysis.
 Data journalism even may require the background to visualize data and to develop algorithms to collect and clean large quantities of data. However, even when individuals have the data and expertise, this is simply not the case for every journalist working with data, meaning coordinating practices must be developed in newsrooms to limit misrepresentation. 
It seems there is an opportunity here to consider possible standardized practices for data journalism. As is, newsrooms may be at risk of spreading misinformation (misinformation is unintentionally misleading, while disinformation actively seeks to mislead), and the pool of people able to enforce editorial standards may be limited.

### Works Cited

Andrew Beers, Melinda McClure Haughey, Ahmer Arif, and Kate Starbird. 2020. Examining the digital toolsets of journalists reportingon disinformation. In Proceedings of Computation + Journalism 2020 (C+J ’20). ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/1122445.1122456

Kate Starbird, Ahmer Arif & Tom Wilson. (2019). Disinformation as Collaborative Work: Surfacing the Participatory Nature of	Strategic Information Operations. PACMHCI. Vol: CSCW. Retrieved from: http://faculty.washington.edu/kstarbi/StarbirdArifWilson_ DisinformationasCollaborativeWork-CameraReady-Preprint.pdf

Melinda McClure Haughey, Meena Devii Muralikumar, Cameron Wood, and Kate Starbird. 2020. On the
Misinformation Beat: Understanding the Work of Investigative Journalists Reporting on Problematic Information Online. Proc. ACM Hum.-Comput. Interact. 4, CSCW2, Article 133 (October 2020), 22 pages. https://doi.org/10.1145/3415204

Oscar Westlund, Alfred Hermida. (2020). Data Journalism and Misinformation. Retrieved from http://www.alfredhermida.me/wp-content/uploads/2020/07/Westlund-and-Hermida-2020-Data-Journalism-and-Misinformation-Accepted-version.pdf




