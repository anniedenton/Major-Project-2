## How can journalists use digital tools to better report on online mis- and disinformation?
In the week following former President Donald Trump’s suspension from major social media platforms, several national news outlets published stories reporting a 73% drop in misinformation on social media. <br/>
![Image](https://github.com/anniedenton/Major-Project-2/blob/gh-pages/images/image1.PNG) <br/>
Both the articles and the original report from research firm Zignal Labs had context for definition of “misinformation,” how that term was quantified, and the pitfalls of those measurements. 
However, what was ultimately circulated widely on social media platforms and on cable news was a watered-down headline that removed key context:<br/>
![Image](https://github.com/anniedenton/Major-Project-2/blob/gh-pages/images/image2.PNG)<br/>
This soundbite, unfortunately, lacks some key context and nuance present in the article, making for a very interesting case study of misinformation reporting.
Twitter suspended over 70,000 accounts in the week after President Trump’s ban, and number of them were not “key allies” of Trump. Many were active or otherwise influential QAnon accounts or even affiliated with unrelated groups, so one can’t make a causal claim from just the Trump suspension. 
Furthermore, the precise measurement of misinformation is problematic.  Though Suspending Pres. Trump’s account likely took a dent out of mis- and disinformation on Twitter, the 73% number is incredibly misleading. We still haven’t quantified yet know the impact of those suspensions, and we certainly hadn’t quantified it in any meaningful way just a week later. The only thing we know for sure is that it likely slowed a certain kind of election fraud discourse.
Using a precise percentage point for an inherently murky figure – per the Zignal Labs report, “misinformation” was measured through keyword terms – is deeply misleading. In a nutshell, a journalist shouldn’t be making claims with precise numbers when the underlying methods are so imprecise. 
This represents the failure of editors and reporters to present information with a headline that reflected the nuance of the article. The misleading headline began to spread devoid of key context for interpreting the claims. The irony of spreading misleading content while reporting on misinformation doesn’t go unnoticed and may highlight an issue of journalism in the digital age. 

### The Current State of Online Misinformation

Modern social media ecosystems, particularly Twitter, are full of unique pitfalls for journalists. Twitter can be an incredibly useful tool for finding sources, discovering new leads, and engaging with an audience. However, the platform is also rife with bad actors that seek to undermine journalistic integrity. Particularly thorny are “strategic information operations,” which are defined in the paper Disinformation as Collaborative Work: Surfacing the Participatory Nature of Strategic Information Operations as efforts by individuals and groups to manipulate and change public opinion by intentionally altering the information environment. 
Fundamentally, these operations seek to undermine the integrity of the digital information space. These operations can be “orchestrated” by a set of paid actors, or “organic,” meaning it arises from a series of individuals in online crowds. The paper finds a shift in recent years towards “organic” efforts. The authors also note that some operations focus on causing distraction or uncertainty in ways that “kill the possibility of debate and a reality-based politics,” rather than attempting to spread any specific message or idea. 
A graph from the authors shows the misinformative theorizing is typically spread by a mix of clickbait news, self-described “alternative” and “independent” media, as well as government-affiliated domains and think tanks associated with specifically pro-Russian stances. This is useful for my project because it outlines many of the common sources of misinformation and ways in which they manifest themselves on social media platforms. Certain design choices of platforms like Twitter also come up briefly, suggesting that amplification technologies, such as the retweet, can provide support to the spread of organic misinformation. 


```markdown
“Journalists and social scientists can find themselves particularly disadvantaged in these circumstances— 
unless there is verifiable proof of intent to deceive, these groups risk reputational, professional and  
legal repercussions when investigating or making claims about information operations.Meanwhile, political
operatives can exploit these professionals’ cautiousness by using plausible deniability as a defense and 
spread misleading content without facing major threats to their own credibility.”
```

### The Mis- and Disinformation Beat

Despite the challenges associated with digital spaces, journalists are increasingly reporting on problematic information in online environments. Experienced internet, social media, and national security reporters are starting to cover this new "beat" full time. In doing this work, journalists aim to inform readers about what is happening online, investigate and debunk false claims, and hold social media companies accountable for the problematic information that spreads on their platforms. Compared to researchers, journalists are often exploring these phenomena on truncated timelines and with fewer resources, yet they rely on some of the same kinds of data and analysis techniques.

### The Rise of Data Journalism

The study “Data Journalism and Misinformation” emphasizes that while data journalism has been envisioned to advance solid ways of knowledge in society, it is contingent on factors such as access to reliable and representative datasets and individuals with the skills to understand and analyze the data. In the study, the authors identify three key components of reliable data journalism. The first is access to relevant reliable datasets, though the study makes it clear that completely unbiased data does not exist and can always be interpreted in a misleading manner and even contribute to misinformation, leading to the second key component, which is the necessity of expertise. Data journalists must have the relevant expertise to process, analyze, and interpret complex data. This requires knowledge in statistics and software, as well as transparency about the process of data analysis. Data journalism even may require the background to visualize data and to develop algorithms to collect and clean large quantities of data. However, even when individuals have the data and expertise, this is simply not the case for every journalist working with data, meaning coordinating practices must be developed in newsrooms to limit misrepresentation. The issues discussed in this article are highly relevant to my work, highlighting the current practices and limitations of computing tools in modern newsrooms. It seems there is an opportunity here to consider possible standardized practices for data journalism. As is, newsrooms may be at risk of spreading misinformation (misinformation is unintentionally misleading, while disinformation actively seeks to mislead), and the pool of people limited to enforce editorial standards may be limited.


### Works Cited

Oscar Westlund, Alfred Hermida. (2020). Data Journalism and Misinformation. Retrieved from http://www.alfredhermida.me/wp-content/uploads/2020/07/Westlund-and-Hermida-2020-Data-Journalism-and-Misinformation-Accepted-version.pdf
Kate Starbird, Ahmer Arif & Tom Wilson. (2019). Disinformation as Collaborative Work: Surfacing the Participatory Nature of	Strategic Information Operations. PACMHCI. Vol: CSCW. Retrieved from: http://faculty.washington.edu/kstarbi/StarbirdArifWilson_ DisinformationasCollaborativeWork-CameraReady-Preprint.pdf

